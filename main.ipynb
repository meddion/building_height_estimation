{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from dataset import BuildingDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from model import get_transform\n",
    "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4481, -0.2339,  1.9366, -0.3357, -0.0180,  2.2093, -1.2660, -0.0180,\n",
      "         0.7344,  1.4809,  1.2207,  0.9514, -1.1552,  0.6162,  0.4376, -1.7551,\n",
      "         2.1437,  1.1757, -0.4266,  0.6852, -0.3957, -1.4685,  2.3706,  0.1332,\n",
      "        -0.6268, -1.7921,  1.3558,  1.8049,  1.9941,  0.7323,  1.4645, -1.4719,\n",
      "         1.0485,  0.0092, -0.6252,  0.2871,  0.1052, -1.0610,  0.1958,  0.4416,\n",
      "        -0.5750,  1.6747, -0.2971,  0.8896, -1.3586, -0.0590, -0.2260,  1.2747,\n",
      "        -1.8033,  0.7617, -0.6508,  0.0710, -0.5775, -0.0805, -0.5263,  0.7292,\n",
      "        -0.2923,  0.9309, -3.1173,  3.0424, -1.4423, -0.0460,  0.2827, -0.4675,\n",
      "        -0.3647,  0.9484,  0.0208,  0.3188, -0.3123,  0.6580, -0.4157, -2.7303,\n",
      "        -0.4883, -0.4634, -0.6228,  1.8601,  0.6374,  1.9224,  0.9352, -0.3682,\n",
      "         0.7273, -1.2279,  0.3356, -0.1458,  0.1916, -0.6775, -1.9377,  0.2285,\n",
      "         1.4374, -0.3871, -0.6581, -0.3516, -2.1266, -0.6455, -1.2120, -0.4273,\n",
      "        -1.0665, -0.9022,  0.5503, -0.0980])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# Example list of tensors of different sizes\n",
    "tensor_list = [torch.randn(2, 3), torch.randn(4), torch.randn(3, 5, 6)]\n",
    "\n",
    "# Step 1: Flatten each tensor\n",
    "flattened_tensors = [t.flatten() for t in tensor_list]\n",
    "\n",
    "# Step 2: Concatenate the flattened tensors\n",
    "continuous_tensor = torch.cat(flattened_tensors)\n",
    "\n",
    "print(continuous_tensor)\n",
    "print(continuous_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for exploration.\n",
    "dataset_test = BuildingDataset(\n",
    "    \"datasets/mlc_training_data/images_annotated/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for exploration.\n",
    "dataset_expl = BuildingDataset(\n",
    "    \"datasets/mlc_training_data/images_annotated/\",\n",
    ")\n",
    "\n",
    "data = [dataset_expl[i] for i in range(10)]\n",
    "# data = [d for d in dataset_expl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, masks, boxes = data[2][0], data[2][1][\"masks\"], data[2][1][\"boxes\"]\n",
    "\n",
    "height_labels = [str(h.item()) for h in data[2][1][\"building_heights\"]]\n",
    "\n",
    "\n",
    "def show_segmentation(img, masks, boxes=None, bcolors=\"red\"):\n",
    "    output_image = draw_segmentation_masks(img, masks.to(torch.bool), alpha=0.8)\n",
    "    if boxes is not None:\n",
    "        output_image = draw_bounding_boxes(\n",
    "            output_image, boxes, height_labels, font_size=15, colors=bcolors\n",
    "        )\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(output_image.permute(1, 2, 0))\n",
    "\n",
    "\n",
    "show_segmentation(img, masks, boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_labels = [d[1][\"building_heights\"] for d in data]\n",
    "height_labels = torch.cat(height_labels).numpy()\n",
    "\n",
    "counts, bins = np.histogram(\n",
    "    height_labels,\n",
    "    bins=[3, 6, 9, 15, 25, 40, 70, 120, 200, max(250, height_labels.max())],\n",
    ")\n",
    "plt.stairs(counts, bins, fill=True)\n",
    "\n",
    "for q in [0.25, 0.5, 0.75, 0.95, 0.99]:\n",
    "    print(f\"Quantile {q}: {np.quantile(height_labels, q)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "dataset = BuildingDataset(\n",
    "    \"datasets/mlc_training_data/images_annotated/\",\n",
    "    transforms=get_transform(train=True),\n",
    ")\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=utils.collate_fn,\n",
    ")\n",
    "\n",
    "# For Training\n",
    "images, targets = next(iter(data_loader))\n",
    "\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "output = model(images, targets)  # Returns losses and detections\n",
    "print(output)\n",
    "\n",
    "# For inference\n",
    "model.eval()\n",
    "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "predictions = model(x)\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import train\n",
    "\n",
    "train(\n",
    "    dataset_root=\"datasets/mlc_training_data/images_annotated\",\n",
    "    num_epochs=20,\n",
    "    train_batch_size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class Engine:\n",
    "    name = \"super shit\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.year = \"2020\"\n",
    "\n",
    "    def start(self):\n",
    "        print(\"engines starts\")\n",
    "\n",
    "    def stop(self):\n",
    "        print(\"engines stops\")\n",
    "\n",
    "\n",
    "class Car:\n",
    "    def __init__(self, engine) -> None:\n",
    "        self.engine = engine\n",
    "\n",
    "    def __getattribute__(self, name: str) -> Any:\n",
    "        if name == \"forward\":\n",
    "            \n",
    "\n",
    "        return getattr(super().__getattribute__(\"engine\"), name)\n",
    "\n",
    "    def stop(self):\n",
    "        print(self.engine.year)\n",
    "        print(self.engine.name)\n",
    "\n",
    "\n",
    "engine = Engine()\n",
    "car = Car(engine)\n",
    "\n",
    "car.stop()\n",
    "car.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bhd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
