{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from dataset import BuildingDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from model import get_transform\n",
    "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Image([[[31, 37, 39,  ...,  2, 20, 32],\n",
       "         [27, 36, 39,  ..., 16, 25, 28],\n",
       "         [27, 33, 36,  ..., 23, 20, 14],\n",
       "         ...,\n",
       "         [25, 18, 11,  ..., 38, 36, 34],\n",
       "         [22, 11,  2,  ..., 34, 36, 35],\n",
       "         [23,  9,  0,  ..., 31, 33, 34]],\n",
       " \n",
       "        [[59, 65, 64,  ..., 21, 35, 47],\n",
       "         [55, 64, 64,  ..., 35, 40, 43],\n",
       "         [55, 61, 61,  ..., 43, 35, 29],\n",
       "         ...,\n",
       "         [75, 68, 61,  ..., 67, 65, 63],\n",
       "         [75, 64, 55,  ..., 63, 62, 62],\n",
       "         [76, 62, 50,  ..., 60, 59, 61]],\n",
       " \n",
       "        [[37, 43, 42,  ..., 15, 30, 42],\n",
       "         [33, 42, 42,  ..., 29, 35, 38],\n",
       "         [33, 39, 39,  ..., 34, 30, 24],\n",
       "         ...,\n",
       "         [37, 30, 23,  ..., 37, 35, 32],\n",
       "         [33, 22, 13,  ..., 33, 33, 31],\n",
       "         [34, 20,  8,  ..., 30, 30, 30]]], dtype=torch.uint8, ),\n",
       " {'boxes': BoundingBoxes([[305., 464., 365., 503.],\n",
       "                 [400., 401., 433., 435.],\n",
       "                 [330., 362., 419., 481.],\n",
       "                 [349., 276., 422., 336.],\n",
       "                 [492., 350., 511., 371.],\n",
       "                 [457., 283., 511., 338.],\n",
       "                 [480., 387., 511., 410.],\n",
       "                 [448., 368., 474., 400.],\n",
       "                 [451., 332., 484., 357.],\n",
       "                 [418., 293., 452., 388.]], format=BoundingBoxFormat.XYXY, canvas_size=[512, 512]),\n",
       "  'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  'masks': Mask([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "  \n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "  \n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "  \n",
       "        ...,\n",
       "  \n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "  \n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "  \n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8),\n",
       "  'building_heights': tensor([9, 9, 6, 9, 6, 6, 6, 6, 6, 6]),\n",
       "  'image_id': 0,\n",
       "  'image_name': 'aaaeexkyyo.png',\n",
       "  'area': tensor([ 2340.,  1122., 10591.,  4380.,   399.,  2970.,   713.,   832.,   825.,\n",
       "           3230.]),\n",
       "  'iscrowd': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  'file_masks': Mask([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "  \n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "  \n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "  \n",
       "        ...,\n",
       "  \n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "  \n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "  \n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8),\n",
       "  'file_boxes': tensor([[451., 332., 484., 357.],\n",
       "          [305., 464., 365., 503.],\n",
       "          [480., 387., 511., 410.],\n",
       "          [448., 368., 474., 400.],\n",
       "          [418., 293., 452., 388.],\n",
       "          [457., 283., 511., 338.],\n",
       "          [330., 362., 419., 481.],\n",
       "          [492., 350., 511., 371.],\n",
       "          [401., 402., 433., 435.],\n",
       "          [349., 276., 422., 336.]]),\n",
       "  'file_area': tensor([  825.,  2340.,   713.,   832.,  3230.,  2970., 10591.,   399.,  1056.,\n",
       "           4380.])})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data for exploration.\n",
    "dataset_test = BuildingDataset(\n",
    "    \"datasets/mlc_training_data/images_annotated/\",\n",
    ")\n",
    "\n",
    "dataset_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for exploration.\n",
    "dataset_expl = BuildingDataset(\n",
    "    \"datasets/mlc_training_data/images_annotated/\",\n",
    ")\n",
    "\n",
    "# data = [d for d in dataset_expl]\n",
    "data = [dataset_expl[i] for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_masks = [d[1][\"file_masks\"] for d in data]\n",
    "file_boxes = [d[1][\"file_boxes\"] for d in data]\n",
    "file_area = [d[1][\"file_area\"] for d in data]\n",
    "\n",
    "\n",
    "masks = [d[1][\"masks\"] for d in data]\n",
    "boxes = [d[1][\"boxes\"] for d in data]\n",
    "area = [d[1][\"area\"] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sfile_area = torch.cat(file_area).sort()[0]\n",
    "# sarea = torch.cat(area).sort()[0]\n",
    "# torch.all(file_masks[0][0].flatten() == masks[0][0].flatten())\n",
    "# print(torch.cat(area))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_segmentation(img, masks, boxes=None, labels=None, bcolors=\"red\"):\n",
    "    output_image = draw_segmentation_masks(img, masks.to(torch.bool), alpha=0.8)\n",
    "    if boxes is not None:\n",
    "        output_image = draw_bounding_boxes(output_image, boxes, labels, colors=bcolors)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(output_image.permute(1, 2, 0))\n",
    "\n",
    "\n",
    "for sample in data[:10]:\n",
    "    img, masks, boxes = sample[0], sample[1][\"masks\"], sample[1][\"boxes\"]\n",
    "    height_labels = [str(h.item()) for h in sample[1][\"building_heights\"]]\n",
    "    show_segmentation(img, masks, boxes, height_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_distribution(values, bins=None):\n",
    "    counts, bins = np.histogram(\n",
    "        values,\n",
    "        bins=bins,\n",
    "    )\n",
    "    plt.stairs(counts, bins, fill=True)\n",
    "\n",
    "    print(\"Min: \", masks.min(), \"Max: \", masks.max())\n",
    "\n",
    "    for q in [0.25, 0.5, 0.75, 0.95, 0.99]:\n",
    "        print(f\"Quantile {q}: {np.quantile(values, q)}\")\n",
    "\n",
    "\n",
    "# heights = [d[1][\"building_heights\"] for d in data]\n",
    "# heights = np.stack(heights, axis=0)\n",
    "# show_distribution(heights, [3, 6, 9, 15, 25, 40, 70, 120, 200, max(250, heights.max())])\n",
    "\n",
    "masks = [len(d[1][\"masks\"]) for d in data]\n",
    "masks = np.stack(masks, axis=0)\n",
    "show_distribution(masks, [3, 6, 9, 15, 25, 40, 70, 120, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[len(d[1][\"masks\"]) for d in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "dataset = BuildingDataset(\n",
    "    \"datasets/mlc_training_data/images_annotated/\",\n",
    "    transforms=get_transform(train=True),\n",
    ")\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=utils.collate_fn,\n",
    ")\n",
    "\n",
    "# For Training\n",
    "images, targets = next(iter(data_loader))\n",
    "\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "output = model(images, targets)  # Returns losses and detections\n",
    "print(output)\n",
    "\n",
    "# For inference\n",
    "model.eval()\n",
    "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "predictions = model(x)\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import train\n",
    "\n",
    "train(\n",
    "    dataset_root=\"datasets/mlc_training_data/images_annotated\",\n",
    "    num_epochs=20,\n",
    "    train_batch_size=10,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bhd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
